# ğŸ§  ViT Explainability: LeGrad, GMAR, and Classical Rollout

This project implements **visual explanations** for Vision Transformers (ViTs) using three methods:

* ğŸ¯ **LeGrad** â€”  An Explainability Method for Vision Transformers via Feature Formation Sensitivity
* ğŸ” **GMAR** â€” Gradient-weighted Multi-head Attention Rollout
* ğŸ§± **Classical Rollout** â€” Layer-wise attention rollout without gradients

All explanations are visualized as **attention heatmaps** overlaid on original input images.
The goal is to analyze **which patches the model attends to** when making predictions.

---

## ğŸ“‚ Project Structure

```
project/
â”œ images/                # Input images (supports .jpg/.png/.jpeg)
â”œ results/               # Output folder for visualizations
â”‚  â”œ legrad/             # Output heatmaps for LeGrad
â”‚  â”œ gmar/               # Output heatmaps for GMAR (with prefix: l1_ or l2_)
â”‚  â”” rollout/            # Output heatmaps for classical attention rollout
â”œ src/                   # Source code directory
â”‚  â”œ gmar.py             # GMAR explanation method
â”‚  â”œ legrad.py           # LeGrad explanation method
â”‚  â”œ rollout.py          # Classical attention rollout
â”‚  â”œ vit.py              # Custom ViT wrapper with attention extraction
â”‚  â”œ main.py             # Main driver for running explanations
â”‚  â”” __pycache__/        # Python bytecode cache
â”œ __pycache__/
â”” readme.md              # This file
```

---

## ğŸš€ How to Use

### 1. Place your input images

Put images in the `images/` folder. Supported formats: `.jpg`, `.jpeg`, `.png`

### 2. Run the project

Navigate to the `src/` directory and run:

```bash
cd src
python main.py
```

You'll be prompted to choose an explanation method:

```bash
Which method? (legrad/gmar/rollout):
```

* `legrad`: Gradient-weighted patch sensitivity
* `gmar`: GMAR with choice of `l1` or `l2` norm
* `rollout`: Classical attention rollout (Abnar & Zuidema, 2020)

---

## ğŸ—¸ï¸ Example Output

Each method saves a heatmap overlay in its respective subfolder under `results/`:

```
results/
â”œ legrad/cat_legrad.png
â”œ gmar/l1_cat_gmar.png
â”œ gmar/l2_dog_gmar.png
â”œ rollout/cat_rollout.png
```

Titles on the images show the predicted class from the model.

---

## âš™ï¸ Model Used

* `google/vit-base-patch16-224` from Hugging Face
* Pretrained on ImageNet-1K
* Predictions and attention weights extracted using `transformers` library

---

## ğŸ“¦ Requirements

Install dependencies via pip:

```bash
pip install torch torchvision transformers matplotlib pillow numpy
```

---

## ğŸ“š References

* [LeGrad: An Explainability Method for Vision Transformers via Feature Formation Sensitivity](arxiv.org/pdf/2404.03214)
* [Quantifying Attention Flow in Transformers](https://arxiv.org/pdf/2005.00928)
* [GMAR: Gradient-weighted Multi-head Attention Rollout (ICCV 2021)](https://arxiv.org/pdf/2504.19414)

---

## âœ¨ Author

Prepared by \Soham Joita
Masterâ€™s student @ OTH Amberg-Weiden
AI for Industrial Applications ğŸ’¡
